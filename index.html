<!DOCTYPE html>
<html lang="en">
<head>
    <link rel="stylesheet" href="static/style.css">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Sign Language Recognition</title>
</head>
<body>
    <h1>Sign Language Recognition</h1>

    <div class="canvas-container">
        <!-- Left Side: Video Feed with Landmarks -->
        <canvas id="outputCanvas" width="640" height="480"></canvas>

        <!-- Right Side: Captured Image -->
        <canvas id="capturedCanvas" width="224" height="224"></canvas>
    </div>

    <div class="button-container">
        <button onclick="captureHand()">Capture</button>
        <button onclick="document.getElementById('fileInput').click()">Import Image</button>
        <input type="file" id="fileInput" accept="image/*" style="display: none;" onchange="importImage(event)">
        <button onclick="clearOutput()">Clear</button>
        <button onclick="predict()">Predict</button>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils"></script>

    <script>
        const canvas = document.getElementById('outputCanvas');
        const ctx = canvas.getContext('2d');
        const capturedCanvas = document.getElementById('capturedCanvas');
        const capturedCtx = capturedCanvas.getContext('2d');

        const video = document.createElement('video');  
        video.setAttribute("autoplay", "");
        video.setAttribute("playsinline", "");

        const hands = new Hands({
            locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });

        hands.setOptions({
            maxNumHands: 1,
            modelComplexity: 1,
            minDetectionConfidence: 0.5,
            minTrackingConfidence: 0.5
        });

        let lastHandBox = null;

        // Default onResults handler for video stream
        const defaultOnResults = (results) => {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmarks = results.multiHandLandmarks[0];

                // Draw landmarks
                drawConnectors(ctx, landmarks, HAND_CONNECTIONS, { color: '#00FF00', lineWidth: 5 });
                drawLandmarks(ctx, landmarks, { color: '#FF0000', lineWidth: 2 });

                // Calculate bounding box
                const xVals = landmarks.map(p => p.x * canvas.width);
                const yVals = landmarks.map(p => p.y * canvas.height);
                const minX = Math.min(...xVals);
                const minY = Math.min(...yVals);
                const maxX = Math.max(...xVals);
                const maxY = Math.max(...yVals);

                // Square bounding box
                const width = maxX - minX;
                const height = maxY - minY;
                const squareSize = Math.max(width, height) + 35; // Add padding

                // Center square region
                const centerX = (minX + maxX) / 2;
                const centerY = (minY + maxY) / 2;

                lastHandBox = {
                    x: Math.max(0, centerX - squareSize / 2),
                    y: Math.max(0, centerY - squareSize / 2),
                    size: Math.min(canvas.width, canvas.height, squareSize)
                };

                ctx.strokeStyle = "blue";
                ctx.lineWidth = 3;
                ctx.strokeRect(lastHandBox.x, lastHandBox.y, lastHandBox.size, lastHandBox.size);
            }
        };

        hands.onResults(defaultOnResults);

        async function startCamera() {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;

                const camera = new Camera(video, {
                    onFrame: async () => {
                        await hands.send({ image: video });
                    },
                    width: 640,
                    height: 480
                });

                camera.start();
            
        }

        function captureHand() {
            if (!lastHandBox) return;


            const squareSize = lastHandBox.size;
            const sourceX = Math.max(0, lastHandBox.x);
            const sourceY = Math.max(0, lastHandBox.y);

            capturedCtx.clearRect(0, 0, capturedCanvas.width, capturedCanvas.height);

            const scale = Math.min(
                capturedCanvas.width / squareSize,
                capturedCanvas.height / squareSize
            );
            const newWidth = squareSize * scale;
            const newHeight = squareSize * scale;
            const offsetX = (capturedCanvas.width - newWidth) / 2;
            const offsetY = (capturedCanvas.height - newHeight) / 2;

            capturedCtx.drawImage(
                video,
                sourceX, sourceY, squareSize, squareSize,
                offsetX, offsetY, newWidth, newHeight
            );
        }

        async function importImage(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = async function(e) {
                const img = new Image();
                img.onload = async function() {
                    // Create a temporary canvas to process the image
                    const tempCanvas = document.createElement('canvas');
                    tempCanvas.width = img.width;
                    tempCanvas.height = img.height;
                    const tempCtx = tempCanvas.getContext('2d');
                    tempCtx.drawImage(img, 0, 0, img.width, img.height);

                    // Create a promise to handle the hand detection results
                    const detectHands = new Promise((resolve) => {
                        // Temporarily override the onResults handler
                        hands.onResults((results) => {
                            // Restore the default handler after processing this image
                            hands.onResults(defaultOnResults);
                            resolve(results);
                        });
                    });

                    // Send the image for hand detection
                    await hands.send({ image: tempCanvas });

                    // Wait for the detection results
                    const results = await detectHands;

                    capturedCtx.clearRect(0, 0, capturedCanvas.width, capturedCanvas.height);

                    if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                        const landmarks = results.multiHandLandmarks[0];

                        // Calculate bounding box
                        const xVals = landmarks.map(p => p.x * img.width);
                        const yVals = landmarks.map(p => p.y * img.height);
                        const minX = Math.min(...xVals);
                        const minY = Math.min(...yVals);
                        const maxX = Math.max(...xVals);
                        const maxY = Math.max(...yVals);

                        // Square bounding box
                        const width = maxX - minX;
                        const height = maxY - minY;
                        const squareSize = Math.max(width, height) + 35; // Add padding

                        // Center square region
                        const centerX = (minX + maxX) / 2;
                        const centerY = (minY + maxY) / 2;

                        const handBox = {
                            x: Math.max(0, centerX - squareSize / 2),
                            y: Math.max(0, centerY - squareSize / 2),
                            size: Math.min(img.width, img.height, squareSize)
                        };

                        // Crop and resize to 224x224
                        const scale = Math.min(
                            capturedCanvas.width / handBox.size,
                            capturedCanvas.height / handBox.size
                        );
                        const newWidth = handBox.size * scale;
                        const newHeight = handBox.size * scale;
                        const offsetX = (capturedCanvas.width - newWidth) / 2;
                        const offsetY = (capturedCanvas.height - newHeight) / 2;

                        capturedCtx.drawImage(
                            img,
                            handBox.x, handBox.y, handBox.size, handBox.size,
                            offsetX, offsetY, newWidth, newHeight
                        );
                    } else {
                        // If no hand is detected, display the whole image scaled to fit
                        const scale = Math.min(capturedCanvas.width / img.width, capturedCanvas.height / img.height);
                        const newWidth = img.width * scale;
                        const newHeight = img.height * scale;
                        const offsetX = (capturedCanvas.width - newWidth) / 2;
                        const offsetY = (capturedCanvas.height - newHeight) / 2;
                        capturedCtx.drawImage(img, offsetX, offsetY, newWidth, newHeight);
                        alert("No hand detected in the image. Displaying the full image.");
                    }
                };
                img.src = e.target.result;
            };
            reader.readAsDataURL(file);
        }

        function clearOutput() {
            capturedCtx.clearRect(0, 0, capturedCanvas.width, capturedCanvas.height);
        }

        async function predict() {
            const capturedImageData = capturedCtx.getImageData(0, 0, capturedCanvas.width, capturedCanvas.height);
            const isEmpty = Array.from(capturedImageData.data).every(value => value === 0);
            if (isEmpty) {
                alert("Please capture or import an image first.");
                return;
            }

            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = 224;
            tempCanvas.height = 224;
            const tempCtx = tempCanvas.getContext('2d');

            tempCtx.drawImage(capturedCanvas, 0, 0, 224, 224);

            const imageData = tempCanvas.toDataURL('image/jpeg');

            try {
                const response = await fetch('/predict', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ image: imageData })
                });

                if (!response.ok) {
                    throw new Error('Prediction failed');
                }

                const data = await response.json();
                alert(`Predicted class: ${data.predicted_class}`);
            } catch (error) {
                console.error('Error:', error);
                alert('Prediction failed. Please try again.');
            }
        }

        startCamera();
    </script>
</body>
</html>